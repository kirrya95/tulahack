{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom PIL import Image\nimport json\nimport os\nfrom tqdm.notebook import tqdm","metadata":{"id":"A_4ACT6rjaa4","execution":{"iopub.status.busy":"2021-11-27T19:07:50.045512Z","iopub.execute_input":"2021-11-27T19:07:50.045833Z","iopub.status.idle":"2021-11-27T19:07:51.611238Z","shell.execute_reply.started":"2021-11-27T19:07:50.045750Z","shell.execute_reply":"2021-11-27T19:07:51.610370Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:08:04.861381Z","iopub.execute_input":"2021-11-27T19:08:04.861649Z","iopub.status.idle":"2021-11-27T19:08:05.574822Z","shell.execute_reply.started":"2021-11-27T19:08:04.861619Z","shell.execute_reply":"2021-11-27T19:08:05.573934Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:08:41.461896Z","iopub.execute_input":"2021-11-27T19:08:41.462193Z","iopub.status.idle":"2021-11-27T19:09:03.904255Z","shell.execute_reply.started":"2021-11-27T19:08:41.462158Z","shell.execute_reply":"2021-11-27T19:09:03.903399Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!gdown \"https://drive.google.com/uc?id=1-0TjTRNHiuz5e2FlDqF4Uw6T4JVsXxMq\"","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:15:07.933798Z","iopub.execute_input":"2021-11-27T19:15:07.934101Z","iopub.status.idle":"2021-11-27T19:15:22.251007Z","shell.execute_reply.started":"2021-11-27T19:15:07.934053Z","shell.execute_reply":"2021-11-27T19:15:22.250067Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!unzip -q \"./Medical+mask.zip\"","metadata":{"id":"mhGauYVpjZeT","execution":{"iopub.status.busy":"2021-11-27T19:16:21.709183Z","iopub.execute_input":"2021-11-27T19:16:21.709887Z","iopub.status.idle":"2021-11-27T19:16:50.211339Z","shell.execute_reply.started":"2021-11-27T19:16:21.709845Z","shell.execute_reply":"2021-11-27T19:16:50.210409Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# picture: torch.Tensor or np.array\n# boxes: indexed object\n# labels: indexed object\ndef draw_pic_with_rect(picture, boxes, labels, n=5):\n    boxes = boxes[:n]\n    labels = labels[:n]\n    if isinstance(picture, torch.Tensor):\n        picture = (picture.detach().squeeze(0) * 256).permute(1, 2, 0).numpy()\n    picture = picture.astype(dtype=np.int)\n\n    fig, ax = plt.subplots(figsize = (15, 15))\n    ax.imshow(picture)\n\n    for box, lab in zip(boxes, labels):\n        rect = matplotlib.patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],\n                                       linewidth=1, edgecolor='r', facecolor='none')\n        ax.text(box[0], box[1], labels, fontsize = 12)\n        ax.add_patch(rect)\n\n    fig.show()","metadata":{"id":"ItBMz3zGi_tR","execution":{"iopub.status.busy":"2021-11-27T19:16:55.624589Z","iopub.execute_input":"2021-11-27T19:16:55.624956Z","iopub.status.idle":"2021-11-27T19:16:55.642997Z","shell.execute_reply.started":"2021-11-27T19:16:55.624913Z","shell.execute_reply":"2021-11-27T19:16:55.639634Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"u5TW8Ie88xrq","outputId":"97453023-4816-4bdb-e9a9-b63324923def","execution":{"iopub.status.busy":"2021-11-27T19:16:56.583737Z","iopub.execute_input":"2021-11-27T19:16:56.584347Z","iopub.status.idle":"2021-11-27T19:16:57.284285Z","shell.execute_reply.started":"2021-11-27T19:16:56.584305Z","shell.execute_reply":"2021-11-27T19:16:57.283320Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"img = Image.open(\"./Medical mask/Medical Mask/images/0010.jpg\")\nimg = np.asarray(img)\nplt.imshow(img)","metadata":{"id":"0nO3BiXlkdtI","outputId":"1e06fcc3-bdac-4b18-afa3-51778983f948","execution":{"iopub.status.busy":"2021-11-27T19:17:03.633956Z","iopub.execute_input":"2021-11-27T19:17:03.634688Z","iopub.status.idle":"2021-11-27T19:17:04.175482Z","shell.execute_reply.started":"2021-11-27T19:17:03.634649Z","shell.execute_reply":"2021-11-27T19:17:04.171876Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"draw_pic_with_rect(img, [[541, 394, 691, 504], [759, 353, 879, 490]], \"mask\")","metadata":{"id":"zN3B5MvNl1Df","outputId":"5985d06e-ee71-4f3c-f85d-be192216b01e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"/content/Medical mask/Medical Mask/annotations/0001.jpg.json\") as f:\n    fff = json.loads(f.read())\nfff","metadata":{"id":"a8Is0q1XkvdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_transform = {\n    \"face_with_mask\": 2,\n    \"mask_colorful\": 1,\n    \"mask_surgical\": 1,\n    \"face_no_mask\": 2,\n    \"face_with_mask_incorrect\": 2,\n    \"face_other_covering\": 2,\n}","metadata":{"id":"BQjD6i_a7FbF","execution":{"iopub.status.busy":"2021-11-27T19:17:08.531806Z","iopub.execute_input":"2021-11-27T19:17:08.532345Z","iopub.status.idle":"2021-11-27T19:17:08.540420Z","shell.execute_reply.started":"2021-11-27T19:17:08.532295Z","shell.execute_reply":"2021-11-27T19:17:08.537053Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"targets = []\n\ncnt = 0\npath_annotations = \"./Medical mask/Medical Mask/annotations\"\nfiles = os.listdir(path_annotations)\nfiles.sort()\n\nfor file in tqdm(files):\n    cnt += 1\n    real_path = os.path.join(path_annotations, file)\n    dick = None\n    with open(real_path, \"r\") as f:\n        dick = json.loads(f.read())\n    element = {\n        \"boxes\": [],\n        \"labels\": [],\n        \"filename\": dick[\"FileName\"],\n    }\n\n    for annotation in dick[\"Annotations\"]:\n        if annotation[\"classname\"] in list(labels_transform.keys()):\n            element[\"boxes\"].append(annotation[\"BoundingBox\"])\n            element[\"labels\"].append(labels_transform[annotation[\"classname\"]])\n            \n    element[\"boxes\"] = torch.tensor(element[\"boxes\"])\n    element[\"labels\"] = torch.tensor(element[\"labels\"])\n    \n    if len(element[\"labels\"]) > 0:\n        targets.append(element)","metadata":{"id":"MryhLfsb0Akz","outputId":"b75dfc87-0946-4fc3-b847-afc4fa0ba00a","execution":{"iopub.status.busy":"2021-11-27T19:17:15.937857Z","iopub.execute_input":"2021-11-27T19:17:15.938394Z","iopub.status.idle":"2021-11-27T19:17:16.431927Z","shell.execute_reply.started":"2021-11-27T19:17:15.938358Z","shell.execute_reply":"2021-11-27T19:17:16.431124Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"id":"N3hoI2RQ8pLR","outputId":"d7618543-f3dd-449f-8aeb-cff5db80c0f0","execution":{"iopub.status.busy":"2021-11-27T19:17:19.049204Z","iopub.execute_input":"2021-11-27T19:17:19.049469Z","iopub.status.idle":"2021-11-27T19:17:19.098960Z","shell.execute_reply.started":"2021-11-27T19:17:19.049442Z","shell.execute_reply":"2021-11-27T19:17:19.098117Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntargets_loader = DataLoader(targets, batch_size=4, shuffle=True, drop_last=True, collate_fn=lambda x: x)","metadata":{"id":"Sz2r83y59WBV","execution":{"iopub.status.busy":"2021-11-27T19:17:24.321536Z","iopub.execute_input":"2021-11-27T19:17:24.322301Z","iopub.status.idle":"2021-11-27T19:17:24.327048Z","shell.execute_reply.started":"2021-11-27T19:17:24.322262Z","shell.execute_reply":"2021-11-27T19:17:24.326293Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\nmodel.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\n\noptimizer = torch.optim.Adam(params, lr=1e-4)","metadata":{"id":"DHwJ2HJ28cuX","execution":{"iopub.status.busy":"2021-11-27T19:17:32.884210Z","iopub.execute_input":"2021-11-27T19:17:32.884478Z","iopub.status.idle":"2021-11-27T19:17:38.031582Z","shell.execute_reply.started":"2021-11-27T19:17:32.884448Z","shell.execute_reply":"2021-11-27T19:17:38.030859Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# The training loop trains the model for the total number of epochs.\n# (1 epoch = one complete pass over the entire dataset)\nnum_epochs = 5\npath_images = \"./Medical mask/Medical Mask/images\"\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.PILToTensor(),                                           \n])\nmodel.train()\nepoch_loss = []\nfor epoch in range(num_epochs):\n    pbar = tqdm(targets_loader)\n    _train_loss = []\n    success_iter = 0\n    for num, batch in enumerate(pbar):\n        images = []\n\n        for el in batch:\n            picture_pil = Image.open(os.path.join(path_images, el[\"filename\"]))\n            images.append(transform(picture_pil).to(device, dtype=torch.float32))\n        \n        t = [{\"boxes\": el[\"boxes\"].to(device, dtype=torch.int64), \n              \"labels\": el[\"labels\"].to(device, dtype=torch.int64),\n              } for el in batch]\n        try:\n            loss_dict = model(images, t)\n        except ValueError:\n            continue\n        success_iter += 1\n\n        losses = sum(loss for loss in loss_dict.values())\n\n        _train_loss.append(losses.item())\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step() \n        del images\n        del t\n        torch.cuda.empty_cache()\n        if num % 50 == 0:\n            epoch_loss.append(np.mean(_train_loss))\n            pbar.set_description(f\"loss_value: {np.mean(_train_loss)}\")\n            _train_loss = []\n    \n    print(success_iter)\n    torch.save(model.state_dict(), f\"xyi{epoch + 2}.pt\")\n    plt.plot(np.arange(len(epoch_loss)), np.array(epoch_loss))","metadata":{"id":"Dd2vTwRk8ehv","outputId":"298ba2e0-b26a-498a-b6cf-6181a2796080","execution":{"iopub.status.busy":"2021-11-27T19:17:47.182052Z","iopub.execute_input":"2021-11-27T19:17:47.182473Z","iopub.status.idle":"2021-11-27T19:44:54.045132Z","shell.execute_reply.started":"2021-11-27T19:17:47.182421Z","shell.execute_reply":"2021-11-27T19:44:54.043953Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# picture: torch.Tensor or np.array\n# boxes: indexed object\n# labels: indexed object\ndef draw_pic_with_rect(picture, boxes, labels, n=5):\n    boxes = boxes[:n]\n    labels = labels[:n]\n    if isinstance(picture, torch.Tensor):\n        picture = picture.detach().cpu().permute(1, 2, 0).numpy()\n    picture = picture.astype(dtype=np.int)\n\n    fig, ax = plt.subplots(figsize = (15, 15))\n    ax.imshow(picture)\n\n    for box, label in zip(boxes, labels):\n        if label == 2:\n            continue\n        rect = matplotlib.patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],\n                                       linewidth=1, edgecolor='r', facecolor='none')\n        ax.text(box[0], box[1], label, fontsize = 12)\n        ax.add_patch(rect)\n\n    fig.show()","metadata":{"id":"ASxAkt18k6u8","execution":{"iopub.status.busy":"2021-11-27T19:49:44.025017Z","iopub.execute_input":"2021-11-27T19:49:44.025798Z","iopub.status.idle":"2021-11-27T19:49:44.034808Z","shell.execute_reply.started":"2021-11-27T19:49:44.025753Z","shell.execute_reply":"2021-11-27T19:49:44.033706Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.eval();","metadata":{"id":"jQa5jBafhjSV","execution":{"iopub.status.busy":"2021-11-27T19:45:10.491817Z","iopub.execute_input":"2021-11-27T19:45:10.492073Z","iopub.status.idle":"2021-11-27T19:45:10.498009Z","shell.execute_reply.started":"2021-11-27T19:45:10.492043Z","shell.execute_reply":"2021-11-27T19:45:10.496135Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"picture_pil = Image.open(\"./Medical mask/Medical Mask/images/0009.jpg\")\nimage = transform(picture_pil).to(device, dtype=torch.float32)\npreds = model(image.unsqueeze(0))\npreds","metadata":{"id":"InXdvPFTYEtq","outputId":"447ed678-7fa0-4870-c1d0-6fbfb0033e60","execution":{"iopub.status.busy":"2021-11-27T19:52:34.632276Z","iopub.execute_input":"2021-11-27T19:52:34.632538Z","iopub.status.idle":"2021-11-27T19:52:34.807479Z","shell.execute_reply.started":"2021-11-27T19:52:34.632510Z","shell.execute_reply":"2021-11-27T19:52:34.806531Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"draw_pic_with_rect(image.cpu().detach().to(dtype=torch.int), preds[0][\"boxes\"].cpu().detach(), preds[0][\"labels\"].cpu().detach().tolist(), 5)","metadata":{"id":"qI6L-v5xjsTQ","outputId":"19cda709-0715-44d4-f389-d937969451c5","execution":{"iopub.status.busy":"2021-11-27T19:52:49.844839Z","iopub.execute_input":"2021-11-27T19:52:49.845112Z","iopub.status.idle":"2021-11-27T19:52:50.822413Z","shell.execute_reply.started":"2021-11-27T19:52:49.845062Z","shell.execute_reply":"2021-11-27T19:52:50.821771Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"picture_pil = Image.open(\"../input/face-mask-detection/images/maksssksksss1.png\")\nimage = transform(picture_pil).to(device, dtype=torch.float32)[:3, :, :]\npreds = model(image.unsqueeze(0))\ndraw_pic_with_rect(image.cpu().detach().to(dtype=torch.int), preds[0][\"boxes\"].cpu().detach(), preds[0][\"labels\"].cpu().detach().tolist(), 15)","metadata":{"id":"o11w-N1AjKdv","execution":{"iopub.status.busy":"2021-11-27T20:12:38.396860Z","iopub.execute_input":"2021-11-27T20:12:38.397163Z","iopub.status.idle":"2021-11-27T20:12:38.972049Z","shell.execute_reply.started":"2021-11-27T20:12:38.397129Z","shell.execute_reply":"2021-11-27T20:12:38.971317Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"!gdown --folder --id \"1kLAh4-si-_8TU7b_P-rTtzlqTyB2CjqD\"","metadata":{"execution":{"iopub.status.busy":"2021-11-27T20:13:15.124339Z","iopub.execute_input":"2021-11-27T20:13:15.124593Z","iopub.status.idle":"2021-11-27T20:13:29.566450Z","shell.execute_reply.started":"2021-11-27T20:13:15.124565Z","shell.execute_reply":"2021-11-27T20:13:29.565618Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"!ls Tulahack","metadata":{"execution":{"iopub.status.busy":"2021-11-27T20:14:49.063929Z","iopub.execute_input":"2021-11-27T20:14:49.064611Z","iopub.status.idle":"2021-11-27T20:14:49.767019Z","shell.execute_reply.started":"2021-11-27T20:14:49.064570Z","shell.execute_reply":"2021-11-27T20:14:49.766202Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"picture_pil = Image.open(\"Tulahack/img1.png\")\nimage = transform(picture_pil).to(device, dtype=torch.float32)[:3, :, :]\npreds = model(image.unsqueeze(0))\ndraw_pic_with_rect(image.cpu().detach().to(dtype=torch.int), preds[0][\"boxes\"].cpu().detach(), preds[0][\"labels\"].cpu().detach().tolist(), 20)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T20:15:23.640565Z","iopub.execute_input":"2021-11-27T20:15:23.640829Z","iopub.status.idle":"2021-11-27T20:15:24.334431Z","shell.execute_reply.started":"2021-11-27T20:15:23.640798Z","shell.execute_reply":"2021-11-27T20:15:24.333788Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"picture_pil = Image.open(\"Tulahack/seva1.jpg\")\nimage = transform(picture_pil).to(device, dtype=torch.float32)[:3, :, :]\npreds = model(image.unsqueeze(0))\ndraw_pic_with_rect(image.cpu().detach().to(dtype=torch.int), preds[0][\"boxes\"].cpu().detach(), preds[0][\"labels\"].cpu().detach().tolist(),5)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T20:16:10.348941Z","iopub.execute_input":"2021-11-27T20:16:10.349675Z","iopub.status.idle":"2021-11-27T20:16:11.338678Z","shell.execute_reply.started":"2021-11-27T20:16:10.349636Z","shell.execute_reply":"2021-11-27T20:16:11.337951Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"picture_pil = Image.open(\"Tulahack/sev2.jpg\")\nimage = transform(picture_pil).to(device, dtype=torch.float32)[:3, :, :]\npreds = model(image.unsqueeze(0))\ndraw_pic_with_rect(image.cpu().detach().to(dtype=torch.int), preds[0][\"boxes\"].cpu().detach(), preds[0][\"labels\"].cpu().detach().tolist(), 20)pg\")\nimage = transform(picture_pil).to(device, dtype=torch.float32)[:3, :, :]\npreds = model(image.unsqueeze(0))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T20:16:28.706033Z","iopub.execute_input":"2021-11-27T20:16:28.706334Z","iopub.status.idle":"2021-11-27T20:16:29.749475Z","shell.execute_reply.started":"2021-11-27T20:16:28.706304Z","shell.execute_reply":"2021-11-27T20:16:29.747880Z"},"trusted":true},"execution_count":76,"outputs":[]}]}